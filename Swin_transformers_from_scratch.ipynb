{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4500f8e9",
      "metadata": {
        "id": "4500f8e9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5e088933",
      "metadata": {
        "id": "5e088933"
      },
      "outputs": [],
      "source": [
        "def window_partition(x, window_size):\n",
        "    B, H, W, C = x.shape\n",
        "    x = x.view(B, H//window_size, window_size, W//window_size, window_size, C)\n",
        "    x = x.permute(0, 1, 3, 2, 4, 5)\n",
        "    x = x.reshape(-1, window_size, window_size, C)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a2b8c01d",
      "metadata": {
        "id": "a2b8c01d"
      },
      "outputs": [],
      "source": [
        "def window_reverse(windows, window, H, W):\n",
        "    B = int(windows.shape[0] / (H//window * W//window))\n",
        "    x = windows.view(B, H//window, W//window, window, window, -1)\n",
        "    x = x.permute(0, 1, 3, 2, 4, 5)\n",
        "    x = x.reshape(B, H, W, -1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "10484ba5",
      "metadata": {
        "id": "10484ba5"
      },
      "outputs": [],
      "source": [
        "class WindowAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, window):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.dim // self.num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.window_size = window\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=True)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "\n",
        "        # Relative positional bias and mask value\n",
        "        coords_h = torch.arange(self.window_size)\n",
        "        coords_w = torch.arange(self.window_size)\n",
        "        coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing=\"ij\"))  # 2, Wh, Ww\n",
        "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
        "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
        "        relative_coords[:, :, 0] += self.window_size - 1  # shift to be positive\n",
        "        relative_coords[:, :, 1] += self.window_size - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size - 1 # This ensures unique indices\n",
        "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
        "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
        "\n",
        "        self.relative_position_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * window - 1) * (2 * window - 1), num_heads))\n",
        "        nn.init.trunc_normal_(self.relative_position_bias_table, std=.02)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B_, N, C = x.shape\n",
        "\n",
        "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B_, num_heads, N, head_dim)\n",
        "\n",
        "        q = q * self.scale\n",
        "        attention = (q @ k.transpose(-2, -1)) # (B_, num_heads, N, N)\n",
        "\n",
        "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
        "            self.window_size * self.window_size, self.window_size * self.window_size, -1) # N, N, num_heads\n",
        "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous() # num_heads, N, N\n",
        "        attention = attention + relative_position_bias.unsqueeze(0) # (B_, num_heads, N, N) + (1, num_heads, N, N)\n",
        "\n",
        "        if mask is not None:\n",
        "            num_window = mask.shape[0]\n",
        "            attention = attention.view(B_ // num_window, num_window, self.num_heads, N, N)\n",
        "            attention = attention + mask.unsqueeze(1).unsqueeze(0)\n",
        "            attention = attention.view(-1, self.num_heads, N, N)\n",
        "\n",
        "        attention = attention.softmax(dim = -1)\n",
        "        output = (attention @ v).transpose(1, 2).reshape(B_, N, C)\n",
        "        output = self.proj(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "05cd5a3f",
      "metadata": {
        "id": "05cd5a3f"
      },
      "outputs": [],
      "source": [
        "class SwinBlock(nn.Module):\n",
        "    def __init__(self, dim, resolution, window, shift, heads):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.resolution = resolution\n",
        "        self.num_window = window\n",
        "        self.shift = shift\n",
        "        self.norm_1 = nn.LayerNorm(dim)\n",
        "        self.attention = WindowAttention(dim, heads, window)\n",
        "        self.norm_2 = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, 4*dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4*dim, dim),\n",
        "        )\n",
        "        H, W = resolution\n",
        "        if shift > 0:\n",
        "            self.mask = self.create_mask(H, W, window, shift)\n",
        "\n",
        "        else:\n",
        "            self.mask = None\n",
        "\n",
        "    def create_mask(self, H, W, window, shift):\n",
        "        img_mask = torch.zeros((1, H, W, 1))\n",
        "        count = 0\n",
        "\n",
        "        for h in (slice(0, -window), (slice(-window, -shift)), slice(-shift, None)):\n",
        "            for w in (slice(0, -window), (slice(-window, -shift)), slice(-shift, None)):\n",
        "                img_mask[:, h, w, :] = count\n",
        "                count += 1\n",
        "\n",
        "        mask = window_partition(img_mask, window)\n",
        "        mask = mask.view(-1, window * window)\n",
        "        mask = mask.unsqueeze(1) - mask.unsqueeze(2)\n",
        "        mask = mask.masked_fill(mask!=0, -10000.0)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, C = x.shape\n",
        "        H, W = self.resolution\n",
        "\n",
        "        residual = x\n",
        "        x = self.norm_1(x)\n",
        "        x = x.view(B, H, W, C)\n",
        "\n",
        "        if self.shift > 0:\n",
        "            x = torch.roll(x, shifts=(-self.shift, -self.shift), dims=(1,2))\n",
        "\n",
        "        window_x = window_partition(x, self.num_window).view(-1, self.num_window*self.num_window, C)\n",
        "\n",
        "        attention_output = self.attention(window_x, self.mask.to(x.device) if self.mask is not None else None)\n",
        "\n",
        "        x = window_reverse(attention_output, self.num_window, H, W)\n",
        "\n",
        "        if self.shift > 0:\n",
        "            x = torch.roll(x, shifts=(self.shift, -self.shift), dims=(1, 2))\n",
        "\n",
        "        x = residual + x.view(B, L, C)\n",
        "\n",
        "        residual_2 = x\n",
        "        x = self.norm_2(x)\n",
        "        x = self.mlp(x)\n",
        "        x = x + residual_2\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9f54fbd7",
      "metadata": {
        "id": "9f54fbd7"
      },
      "outputs": [],
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "        self.reduction = nn.Linear(4*dim, 2*dim, bias=False)\n",
        "        self.norm = nn.LayerNorm(4*dim)\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        B, L, C = x.shape\n",
        "        x = x.view(B, H, W, C)\n",
        "\n",
        "        x_0 = x[:, 0::2, 0::2, :]\n",
        "        x_1 = x[:, 1::2, 0::2, :]\n",
        "        x_2 = x[:, 0::2, 1::2, :]\n",
        "        x_3 = x[:, 1::2, 1::2, :]\n",
        "\n",
        "        x_0 = x_0.reshape(B, -1, C)\n",
        "        x_1 = x_1.reshape(B, -1, C)\n",
        "        x_2 = x_2.reshape(B, -1, C)\n",
        "        x_3 = x_3.reshape(B, -1, C)\n",
        "\n",
        "        x = torch.cat([x_0, x_1, x_2, x_3], -1)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        return x, H//2, W//2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8e1a6c47",
      "metadata": {
        "id": "8e1a6c47"
      },
      "outputs": [],
      "source": [
        "class TwoStageSwinMNIST(nn.Module):\n",
        "    def __init__(self, embed_dim= 48, heads=3, window=7, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embed_dim\n",
        "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=2, stride=2)\n",
        "        initial_resolution = (14, 14)\n",
        "\n",
        "        # Stage 1\n",
        "        self.stage_1_blocks = nn.Sequential(\n",
        "            SwinBlock(embed_dim, initial_resolution, heads=heads, window=window, shift=0),\n",
        "            SwinBlock(embed_dim, initial_resolution,  heads=heads, window=window, shift=3)\n",
        "        )\n",
        "\n",
        "        self.patch_merge = PatchMerging(embed_dim)\n",
        "        merged_dim = embed_dim * 2\n",
        "        stage_2_resolution = (initial_resolution[0]//2, initial_resolution[1]//2)\n",
        "\n",
        "        # Stage 2\n",
        "        self.stage_2_blocks = nn.Sequential(\n",
        "            SwinBlock(merged_dim, stage_2_resolution, heads=heads, window=window, shift=0),\n",
        "            SwinBlock(merged_dim, stage_2_resolution, heads=heads, window=window, shift=window // 2)\n",
        "        )\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(merged_dim)\n",
        "        self.fully_connected_layer = nn.Linear(merged_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        L = H * W\n",
        "\n",
        "        x = self.stage_1_blocks(x)\n",
        "        x, H, W = self.patch_merge(x, H, W)\n",
        "        L = H * W\n",
        "        C = C * 2\n",
        "\n",
        "        x = self.stage_2_blocks(x)\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        x = x.mean(dim = 1)\n",
        "        x = self.fully_connected_layer(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3c27ed7c",
      "metadata": {
        "id": "3c27ed7c"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307, ), (0.3081,))\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(\"./data\", train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=256, shuffle=False)\n",
        "\n",
        "model = TwoStageSwinMNIST().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8b7e82ce",
      "metadata": {
        "id": "8b7e82ce"
      },
      "outputs": [],
      "source": [
        "def test(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img, lable in test_loader:\n",
        "            img = img.to(device)\n",
        "            lable = lable.to(device)\n",
        "\n",
        "            output = model(img)\n",
        "            pred = output.argmax(1)\n",
        "            correct += pred.eq(lable).sum().item()\n",
        "            total += lable.size(0)\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "046b4a6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "046b4a6a",
        "outputId": "bca2be90-b3ff-4ef8-87bc-f1cbeb7a3dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 22.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Accuracy =  89.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 22.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Accuracy =  94.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Accuracy =  95.19999999999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Accuracy =  94.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Accuracy =  95.87\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    for img, lable in tqdm(train_loader):\n",
        "        img = img.to(device)\n",
        "        lable = lable.to(device)\n",
        "\n",
        "        output = model(img)\n",
        "        loss = loss_fn(output, lable)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    acc = test(model)\n",
        "    print(\"Epoch\", epoch + 1, \"Accuracy = \", acc * 100)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}